#!/usr/bin/python
import eventlet
eventlet.monkey_patch()

import json
import logging
import log
import time
import urllib2

from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk

from rackspace_monitoring.providers import get_driver
from rackspace_monitoring.types import Provider

import limiters
from config import get_config
from models import Entity
from parser import get_parser
from query import load_entity_types
from template import get_templates

logger = logging.getLogger('grafanizer')


def get_token(config):
    """
    Gets an auth token. Usually, the rackspace monitoring driver takes
    care of this, but there has been a bug where service catalogs have
    not been configured correctly for some tenants and report as
    have no endpoints.

    """
    data = {
        'auth': {
            'RAX-KSKEY:apiKeyCredentials': {
                'username': config['datasource']['username'],
                'apiKey': config['datasource']['api_key']
            }
        }
    }

    headers = {
        'Content-type': 'application/json',
        'Accept': 'application/json'
    }

    url = 'https://auth.api.rackspacecloud.com:443/v2.0/tokens'

    req = urllib2.Request(url, json.dumps(data), headers)
    resp = urllib2.urlopen(req)
    resp = resp.read()
    resp = json.loads(resp)
    return resp['access']['token']['id']


def get_instance(username, api_key, url, auth_url=None, auth_token=None):
    """
    Returns an instance of the Rackspace Cloud Monitoring driver.

    @param username - String username
    @param api_key - String api key
    @param url - String api url
    @param auth_url - String auth url
    @param auth_token - String auth token
    @return - driver instance

    """
    driver = get_driver(Provider.RACKSPACE)
    kwargs = {
        'ex_force_base_url': url,
        'ex_force_auth_url': auth_url,
        'ex_force_auth_token': auth_token
    }
    return driver(username, api_key, **kwargs)


def get_entity(api_url, auth_token, driver_entity):
    """
    Gets one entity with all checks and metrics included. An api call to list
    all entities should have already been made. Pass the auth token and api
    url from that call to this one to avoid reauth. In addition, this function
    is meant to be called from a multi green thread environment.

    @param api_url - String api url
    @param auth_token - String auth token
    @param driver_entity - Entity instance from driver.
    @return - Instance of entity model with checks and metrics included.

    """
    driver = get_instance(None, None, api_url, auth_token=auth_token)
    return Entity(driver, driver_entity)


def get_entity_pile(config):
    """
    Returns an iterable greenpile which will contain instances of
    the entity model. Will ultimately use one green thread per entity
    up to a maximum of pilesize.

    @param config - Dictionary with configuration
    @return - eventlet.GreenPile

    """
    auth_token = None
    api_url = None
    try:
        driver = get_instance(config['datasource']['username'],
                              config['datasource']['api_key'],
                              config['datasource']['url'],
                              auth_url=None, auth_token=None)
    except Exception as e:
        # Handle bug where tenant does not have endpoints in service catalog
        # Need to manually gather an auth token and create the api url which
        # includes the tenant
        if "Service catalog contains no endpoints" in e.message:
            api_url = "%s/%s" % (
                config['datasource']['url'],
                config['datasource']['tenant']
            )
            auth_token = get_token(config)
            driver = get_instance(None, None, api_url, auth_token=auth_token)
        else:
            raise

    limiters.get_limiter('api').get_token()
    driver_entities = driver.list_entities()

    # Save the auth token and api url for use in other driver instances
    # if we do not already have them.
    if not auth_token:
        auth_token = driver.connection.auth_token
    if not api_url:
        api_url = driver.connection.get_endpoint()

    entity_pile = eventlet.GreenPile(config.get('pool_size'))
    for driver_entity in driver_entities:
        entity_pile.spawn(get_entity, api_url, auth_token, driver_entity)
    return entity_pile


def grafanize():
    """
    Does all of the things.
    Loads configuration
    Gets the entities.
    Persists templates to elastic search.

    """
    start = time.time()
    logger.info("Starting...")

    args = get_parser().parse_args()

    config = get_config(args)

    templates = get_templates(config['template_dir'], file_=args.file)
    if not len(templates):
        logger.info("No templates loaded.")
        exit()

    load_entity_types(config['template_dir'])

    # End here if we are only validating or we have no templates.
    if args.validate:
        exit()

    retries = config.get('retries')
    retry_interval = config.get('retry_interval')
    logger.info("Rate tokens: %s" % config['api_limit_rate_tokens'])
    logger.info("Rate seconds: %s" % config['api_limit_rate_seconds'])
    limiters.start_limiter('api',
        config['api_limit_rate_tokens'],
        config['api_limit_rate_seconds']
    )

    logger.info("Rate: %s" % limiters.get_limiter('api').fill_rate)

    for i in xrange(1, retries + 1):
        logger.debug("Attempt %s" % i)
        try:
            entity_count = 0
            entity_pile = get_entity_pile(config)

            for e in entity_pile:
                entity_count = entity_count + 1
                for t in templates:
                    t.consume(e)

            es = Elasticsearch()
            ops = []
            for t in templates:
                ops += t.es_ops()

            count, _ = bulk(es, ops)
            logger.info(
                "Created %s dashboards from %s entities in %s seconds." % (
                    count,
                    entity_count,
                    time.time() - start
                )
            )
            logger.info('Api rate: %s calls per min'
                        % limiters.get_limiter('api').get_usage_rate())
            break
        except:
            logger.exception("Unable to grafanize:")
            logger.info("Sleeping for %s seconds." % retry_interval)
            time.sleep(retry_interval)

if __name__ == '__main__':
    try:
        grafanize()
    except Exception:
        logger.exception("Unable to recover")
